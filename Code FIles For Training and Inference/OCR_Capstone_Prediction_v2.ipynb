{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Praxis Form Inner Box - v4.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-30T14:03:42.196485Z",
          "start_time": "2020-03-30T14:03:41.350742Z"
        },
        "id": "qBy3OqQi3Uvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for box detaction\n",
        "\n",
        "import os\n",
        "import time\n",
        "import statistics\n",
        "import cv2\n",
        "from scipy.stats import mode\n",
        "\n",
        "# for image preprocess\n",
        "import pandas as pd\n",
        "from PIL import Image,ImageFilter\n",
        "import numpy as np\n",
        "import sys\n",
        "import csv\n",
        "import PIL.ImageOps\n",
        "\n",
        "# for model\n",
        "# %tensorflow_version 1.x  # For colab\n",
        "import tensorflow\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0wpbiL3-26M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "3bfcdb05-7ac8-4acd-f86c-4a2dca8102de"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sYpbbEJQIQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=pd.read_excel(\"/content/gdrive/My Drive/Colab Notebooks/results/Inference/Labels Inference - 47 Labels.xlsx\",index_col=\"Sr. No.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A218MpmNcyo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c0e581f0-2478-415a-d05c-f553ace913b7"
      },
      "source": [
        "#print(\"Loading Model\")\n",
        "model = load_model(\"/content/gdrive/My Drive/Colab Notebooks/model_letters_digits_space_sc_88.h5\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTzkSSNM3Uv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # image pre process\n",
        "\n",
        "# def preprocess(data,img,num_images):\n",
        "\n",
        "#   # Convert cv2 image to PIL image\n",
        "#   #cv2_img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "#   image = Image.fromarray(img)\n",
        "#   image = image.crop((4, 3, image.size[0]-4, image.size[0]-4))     # im.crop((left, top, right, bottom)) \n",
        "#   img_resized = image.resize((78,78))\n",
        "#   img_resized=PIL.ImageOps.invert(img_resized)\n",
        "#   # img_file = img_resized.filter(ImageFilter.MedianFilter())\n",
        "#   threshold = 80\n",
        "#   img_file = img_resized.point(lambda p: p > threshold and 255)\n",
        "\n",
        "#   # Save Greyscale values\n",
        "#   value = np.asarray(img_file.getdata(), dtype=np.int).reshape((img_file.size[1], img_file.size[0]))\n",
        "#   value = value.flatten()\n",
        "  \n",
        "#   # To improve image quality on 4 top and bottom lines\n",
        "#   for i in range (0,4):\n",
        "#     if (mode(value[78*i:78*(i+1)])[0]>200 or (mode(value[78*i:78*(i+1)])[0] < 80 and mode(value[78*i:78*(i+1)])[1][0] < 54)):\n",
        "#         value[78*i:78*(i+1)]=0\n",
        "#     if (mode(value[-78*(i+1):-78*(i)-1])[0]>200 or (mode(value[-78*(i+1):-78*(i)-1])[0] < 80 and mode(value[-78*(i+1):-78*(i)-1])[1][0] < 54)):\n",
        "#         value[-78*(i+1):-78*(i)-1]=0\n",
        "#   data.loc[num_images] = value\n",
        "#   #print(value)\n",
        "#   num_images += 1\n",
        "#   #print(\"image preprocessed\")\n",
        "#   return (data,num_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mQQ34dLoDM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image pre process\n",
        "\n",
        "def preprocess(img,value):\n",
        "\n",
        "  # Convert cv2 image to PIL image\n",
        "  #cv2_img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "  image = Image.fromarray(img)\n",
        "  image = image.crop((4, 3, image.size[0]-4, image.size[0]-4))     # im.crop((left, top, right, bottom)) \n",
        "  img_resized = image.resize((78,78))\n",
        "  img_resized=PIL.ImageOps.invert(img_resized)\n",
        "  # img_file = img_resized.filter(ImageFilter.MedianFilter())\n",
        "  threshold = 80\n",
        "  img_file = img_resized.point(lambda p: p > threshold and 255)\n",
        "\n",
        "  # Save Greyscale values\n",
        "  value = np.asarray(img_file.getdata(), dtype=np.int).reshape((img_file.size[1], img_file.size[0]))\n",
        "  value = value.flatten()\n",
        "  \n",
        "  # To improve image quality on 4 top and bottom lines\n",
        "  for i in range (0,4):\n",
        "    if (mode(value[78*i:78*(i+1)])[0]>200 or (mode(value[78*i:78*(i+1)])[0] < 80 and mode(value[78*i:78*(i+1)])[1][0] < 54)):\n",
        "      value[78*i:78*(i+1)]=0\n",
        "    if (mode(value[-78*(i+1):-78*(i)-1])[0]>200 or (mode(value[-78*(i+1):-78*(i)-1])[0] < 80 and mode(value[-78*(i+1):-78*(i)-1])[1][0] < 54)):\n",
        "      value[-78*(i+1):-78*(i)-1]=0\n",
        "  return(value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbIe3YjL3UwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image prediction\n",
        "\n",
        "def inference(test,count):\n",
        "  test_image = []\n",
        "\n",
        "  # Saivng all images in X_test\n",
        "  for i in tqdm(range(test.shape[0])):\n",
        "    im_buf = test.values[i][0:]\n",
        "    im_array = np.int8(np.reshape(im_buf, (78, 78))) \n",
        "    #img = image.load_img(train.iloc[:,1:].as_matrix().astype('str'), target_size=(64,64,1), color_mode='grayscale')\n",
        "    img = image.img_to_array(im_array)\n",
        "    img = img/255\n",
        "    test_image.append(img)\n",
        "  X_test = np.array(test_image)\n",
        "  X_test = np.repeat(X_test, 3, -1)\n",
        "\n",
        "\n",
        "  print(\"Predicting\")\n",
        "  pred=model.predict(X_test)\n",
        "  # for i in pred:\n",
        "  #     print(i)\n",
        "      \n",
        "  output=np.argmax(pred, axis=1)\n",
        "  # print(\"Reading Lables\")\n",
        "  # labels=pd.read_excel(\"/content/gdrive/My Drive/Colab Notebooks/results/Inference/Labels Inference - 47 Lables.xlsx\",index_col=\"Sr. No.\")\n",
        "  # print(\"out\")\n",
        "  col=['pred']\n",
        "  section=out=pd.DataFrame(columns=['pred'])\n",
        "  row=0\n",
        "  for i in output:\n",
        "    section.loc[row]=labels.iloc[i].values\n",
        "    row+=1\n",
        "    #print(labels.iloc[i].values)\n",
        "  \n",
        "  section.to_csv(\"/content/gdrive/My Drive/Colab Notebooks/results/Inference/section\"+str(count)+\".csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-30T14:03:43.028079Z",
          "start_time": "2020-03-30T14:03:42.976223Z"
        },
        "id": "j1Q6o9-r3UwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the image in black and white (0 - b/w, 1 - color).\n",
        "def inner_box(img,count,height):\n",
        "  # img is image\n",
        "  # Count is section 0-5\n",
        "  # height is image height\n",
        "  # number is image number from the batch\n",
        "\n",
        "  #Invert the image to be white on black for compatibility with findContours function.\n",
        "  imgray = 255 - img\n",
        "\n",
        "# Using different combination of dilation and blur to get as much as contours possible\n",
        "\n",
        "  # rects1\n",
        "  \n",
        "  kernel = np.ones((1,10),np.uint8)\n",
        "  imgray1 = cv2.dilate(imgray,kernel,iterations = 1)\n",
        "  kernel = np.ones((10,1),np.uint8)\n",
        "  imgray1 = cv2.dilate(imgray1,kernel,iterations = 1)\n",
        "  thresh1 = cv2.adaptiveThreshold(imgray1, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,15,2)\n",
        "\n",
        "  #Find all the contours in thresh. \n",
        "  contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  rects1 = [cv2.boundingRect(cnt) for cnt in contours]\n",
        "\n",
        "\n",
        "  # rects2 imp\n",
        "  imgray2 = cv2.blur(imgray,(10,3))\n",
        "  thresh2 = cv2.adaptiveThreshold(imgray2, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,15,2)\n",
        "\n",
        "  \n",
        "  #Find all the contours in thresh. \n",
        "  contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  rects2 = [cv2.boundingRect(cnt) for cnt in contours]\n",
        "\n",
        "  # rects3 imp\n",
        "  imgray3 = cv2.blur(imgray,(3,10))\n",
        "  thresh3 = cv2.adaptiveThreshold(imgray3, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,15,2)\n",
        "  \n",
        "  #Find all the contours in thresh. \n",
        "  contours, hierarchy = cv2.findContours(thresh3, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  rects3 = [cv2.boundingRect(cnt) for cnt in contours]\n",
        "\n",
        "  #rects4 imp\n",
        "  kernel = np.ones((2,7),np.uint8)\n",
        "  imgray4 = cv2.dilate(imgray,kernel,iterations = 1)\n",
        "  thresh4 = cv2.adaptiveThreshold(imgray4, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,15,2)\n",
        "  \n",
        "  #Find all the contours in thresh.\n",
        "  contours, hierarchy = cv2.findContours(thresh4, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  rects4 = [cv2.boundingRect(cnt) for cnt in contours]\n",
        "\n",
        "  \n",
        "  #rects5 imp\n",
        "  kernel = np.ones((7,2),np.uint8)\n",
        "  imgray5 = cv2.dilate(imgray,kernel,iterations = 1)\n",
        "  thresh5 = cv2.adaptiveThreshold(imgray5, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,15,2)\n",
        "  \n",
        "  #Find all the contours in thresh.\n",
        "  contours, hierarchy = cv2.findContours(thresh5, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  rects5 = [cv2.boundingRect(cnt) for cnt in contours]\n",
        "  \n",
        "  \n",
        "# Defining function to filter sections for different size sections\n",
        "\n",
        "  def filterrects1(raw_rects,rects):\n",
        "      for i in raw_rects:\n",
        "          if (abs(i[2]-i[3])<10):\n",
        "              if (i[2]>height/75 and i[2]<height/40 and i[3]>height/75 and i[3]<height/40 and i not in rects):\n",
        "                  rects.append(i)\n",
        "      return(rects)\n",
        "  \n",
        "  def filterrects2(raw_rects,rects):\n",
        "      for i in raw_rects:\n",
        "          if (i[2]>height/40 and i[2]<height/25 and i[3]>height/40 and i[3]<height/25 and i not in rects):\n",
        "              rects.append(i)\n",
        "      return(rects)\n",
        "  \n",
        "# checking the section number and calling function accordingly.\n",
        "  if count!=0:\n",
        "      rects=[]\n",
        "      rects=filterrects1(rects1,rects)\n",
        "      rects=filterrects1(rects2,rects)\n",
        "      rects=filterrects1(rects3,rects)\n",
        "      rects=filterrects1(rects4,rects)\n",
        "      rects=filterrects1(rects5,rects)\n",
        "                  \n",
        "  else:\n",
        "      rects=[]\n",
        "      rects=filterrects2(rects1,rects)\n",
        "      rects=filterrects2(rects2,rects)\n",
        "      rects=filterrects2(rects3,rects)\n",
        "      rects=filterrects2(rects4,rects)\n",
        "      rects=filterrects2(rects5,rects)\n",
        "\n",
        "  rects_final=rects.copy()\n",
        "  \n",
        "# Removing the sections which are overlapping\n",
        "  for i in range(0,len(rects)-1):\n",
        "      try:\n",
        "          for j in range(i+1,len(rects)):\n",
        "              if (abs(rects[i][0] - rects[j][0]) < 15 and abs(rects[i][1] - rects[j][1]) < 15):\n",
        "                  if (rects[i][2] < rects[j][2] and rects[i][3] < rects[j][3]):\n",
        "                      rects_final.remove(rects[j])\n",
        "                  else:\n",
        "                      rects_final.remove(rects[i])\n",
        "      except:\n",
        "          continue\n",
        "#     print(len(rects_final))\n",
        "  rects=rects_final.copy()\n",
        "\n",
        "  #Calculate the combined bounding rectangle points.\n",
        "  top_x = min([x for (x, y, w, h) in rects])\n",
        "  top_y = min([y for (x, y, w, h) in rects])\n",
        "  bottom_x = max([x+w for (x, y, w, h) in rects])\n",
        "  bottom_y = max([y+h for (x, y, w, h) in rects])\n",
        "\n",
        "\n",
        "  from scipy.stats import mode\n",
        "  h_mode = mode([h for (x, y, w, h) in rects])[0]\n",
        "  #w_mode = mode([w for (x, y, w, h) in rects])[0]\n",
        "  n=int(((bottom_y-top_y)/h_mode))\n",
        "\n",
        "# Sorting the sections in increasing order as they occur in image\n",
        "  import operator\n",
        "  temp=[]\n",
        "  b = [[] for i in range(0, n+3)]\n",
        "  for j in range (1,n+3):\n",
        "    for i in rects:\n",
        "        x=i[0]\n",
        "        y=i[1]\n",
        "        w=i[2]\n",
        "        h=i[3]\n",
        "          \n",
        "    # Keeping constraint on y and sorting as per x pixels\n",
        "        if ((y > bottom_y-h_mode*j-h_mode/2.5) and (i not in temp)):\n",
        "          b[j].append(i)\n",
        "          temp.append(i)\n",
        "        b[j]=sorted(b[j],key=lambda x:(-x[0]))\n",
        "  #b.pop(0)\n",
        "  tar_dir=r\"/content/gdrive/My Drive/Colab Notebooks/Output/Inner/\"+str(2)+\"/\"+str(count)+\"/\"\n",
        "  if not os.path.exists(tar_dir):\n",
        "      #print(\"here2\")\n",
        "    os.makedirs(tar_dir) \n",
        "\n",
        "# Traversing through each section and saving and predicting each contour\n",
        "  count1=0\n",
        "\n",
        "# dataframe to store all images values\n",
        "  columnNames=[]\n",
        "  for i in range (0,6084):\n",
        "    columnNames.append(i)\n",
        "  print(\"count is\",count)\n",
        "  data=pd.DataFrame(columns = columnNames)\n",
        "  num_images=0\n",
        "  for i in b:\n",
        "    for j in i:\n",
        "      try:\n",
        "        x=j[0]\n",
        "        y=j[1]\n",
        "        w=j[2]\n",
        "        h=j[3]\n",
        "\n",
        "#To append image in dataframe\n",
        "        value=[]\n",
        "        cv2.imwrite(tar_dir+str(count1)+\".jpg\",img[y-2:y+h+2,x-2:x+w+2])\n",
        "        value=preprocess(img[y-2:y+h+2,x-2:x+w+2],value)\n",
        "        #data,num_images=preprocess(data,img[y-2:y+h+2,x-2:x+w+2],num_images)\n",
        "        data.loc[num_images]=value\n",
        "        num_images += 1\n",
        "        time.sleep(0.01)\n",
        "        count1+=1\n",
        "      except:\n",
        "        continue\n",
        "# To Infer the datframe boxes\n",
        "    #print(\"inferecing\")\n",
        "  # if data.empty == True:\n",
        "  #   continue\n",
        "  # else:\n",
        "  #   #print(data.head())\n",
        "  print(data.shape)\n",
        "  inference(data,count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-30T14:03:43.609183Z",
          "start_time": "2020-03-30T14:03:43.479112Z"
        },
        "id": "Te4lzc5v3UwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to check if all major boxes came and try to get correct one by hard code if some error.\n",
        "\n",
        "def validrects(rects3):\n",
        "    if len (rects3)!=6:\n",
        "        rects_f=[]\n",
        "        \n",
        "        # saving all cooredinates of large box by manuualy calculating x,y,w,h using height of whole image and 1st box\n",
        "        first=rects3[0]\n",
        "        second=(first[0],first[1]+first[3]+round(height/159.41),round(first[2]*2.05),round(height/11.13))\n",
        "        third=(first[0],second[1]+second[3]+round(height/159.41),round(first[2]*2.05),round(height/4.45))\n",
        "        fourth=(first[0]+(round(first[2]*2.05*5/35)),third[1]+third[3]+round(height/159.41),round(first[2]*2.05),round(height/8.37))\n",
        "        fifth=(first[0]+(round(first[2]*2.05*5/35)),fourth[1]+fourth[3]+round(height/159.41),round(first[2]*2.05),round(height/11.89))\n",
        "        sixth=(first[0]+(round(first[2]*2.05*4/35)),fifth[1]+fifth[3]+round(height/159.41),round(first[2]*2.05),round(height/8.77))\n",
        "        rects_f=[first,second,third,fourth,fifth,sixth]\n",
        "        return rects_f\n",
        "    \n",
        "    elif (len (rects3)==6 and  rects3[1][3]/rects3[0][3] > 1.25 and rects3[2][3]/rects3[0][3] > 3.25 and \n",
        "    rects3[3][3]/rects3[0][3] > 1.50 and rects3[4][3]/rects3[0][3] > 1.25 and rects3[5][3]/rects3[0][3] > 1.50):\n",
        "        return rects3\n",
        "    else:\n",
        "        rects_f=[]\n",
        "        # saving all cooredinates of large box by manuualy calculating x,y,w,h using height of whole image and 1st box\n",
        "        first=rects3[0]\n",
        "        second=(first[0],first[1]+first[3]+round(height/159.41),round(first[2]*2.05),round(height/11.13))\n",
        "        third=(first[0],second[1]+second[3]+round(height/159.41),round(first[2]*2.05),round(height/4.45))\n",
        "        fourth=(first[0]+(round(first[2]*2.05*5/35)),third[1]+third[3]+round(height/159.41),round(first[2]*2.05),round(height/8.37))\n",
        "        fifth=(first[0]+(round(first[2]*2.05*5/35)),fourth[1]+fourth[3]+round(height/159.41),round(first[2]*2.05),round(height/11.89))\n",
        "        sixth=(first[0]+(round(first[2]*2.05*4/35)),fifth[1]+fifth[3]+round(height/159.41),round(first[2]*2.05),round(height/8.77))\n",
        "        rects_f=[first,second,third,fourth,fifth,sixth]\n",
        "        return rects_f\n",
        "        return rects3\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-30T14:05:23.145071Z",
          "start_time": "2020-03-30T14:03:44.019074Z"
        },
        "id": "cZL_ns943Uwd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "2dc82514-3d26-4bc9-ba2a-7fb4aef7daf6"
      },
      "source": [
        "#Load the image in black and white (0 - b/w, 1 - color).\n",
        "number=2\n",
        "img = cv2.imread(r'/content/gdrive/My Drive/Colab Notebooks/results/Inference/form/'+str(number)+'.jpg', 0)\n",
        "\n",
        "#Get the height and width of the image.\n",
        "height, width = img.shape[:2]\n",
        "\n",
        "#Invert the image to be white on black for compatibility with findContours function.\n",
        "imgray = 255 - img\n",
        "\n",
        "# Remove noise using dilate and thershold\n",
        "thresh = cv2.adaptiveThreshold(imgray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,15,2)\n",
        "kernel = np.ones((2,2),np.uint8)\n",
        "thresh = cv2.dilate(thresh,kernel,iterations = 1)\n",
        "\n",
        "#Find all the contours in thresh. \n",
        "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "#Find bounding rectangles for each contour.\n",
        "rects = [cv2.boundingRect(cnt) for cnt in contours]\n",
        "rects2=[]\n",
        "count=0\n",
        "for i in rects:\n",
        "    # hierarchy [Next, Previous, First_Child, Parent]\n",
        "    if (hierarchy[0][count][2]>0 and hierarchy[0][count][3]<0):   # condn that contour is parent and have child.\n",
        "        if (i[2]>thresh.shape[1]/3 and i[2] < thresh.shape[1]):   # condn on width of contours\n",
        "            rects2.append(i)\n",
        "    count+=1\n",
        "h_mode = mode([h for (x, y, w, h) in rects2])[0]\n",
        "\n",
        "# to remove noisy contour i.e. which are small in height if these\n",
        "if h_mode < height/20:\n",
        "    rects2=[]\n",
        "    count=0\n",
        "    for i in rects:\n",
        "        if (hierarchy[0][count][2]>0):\n",
        "            if (i[2]>thresh.shape[1]/3 and i[2] < thresh.shape[1] and i[3] > h_mode*1.2 ):\n",
        "                rects2.append(i)\n",
        "        count+=1\n",
        "\n",
        "# to remove duplicate contours having very less coordinate difference\n",
        "rects3=rects2.copy()\n",
        "for i in range(0,len(rects2)-1):\n",
        "    try:\n",
        "        for j in range(i+1,len(rects2)):\n",
        "            if (rects2[i][1] - rects2[j][1] <50):\n",
        "                if rects2[i][2]>rects2[j][2]:\n",
        "                    value=rects2[j]\n",
        "                    rects3.remove(value)\n",
        "                else :\n",
        "                    value=rects2[i]\n",
        "                    rects3.remove(value)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "# sort in correct order\n",
        "rects3=sorted(rects3,key=lambda x:(x[1]))\n",
        "rects3=validrects(rects3)\n",
        "# saving all\n",
        "count=0\n",
        "#print(len(rects3))\n",
        "# To fetch inner box\n",
        "for j in rects3:\n",
        "  # try:\n",
        "    x=j[0]\n",
        "    y=j[1]\n",
        "    w=j[2]\n",
        "    h=j[3]\n",
        "    if not os.path.exists(r\"/content/gdrive/My Drive/Colab Notebooks/Output/Outer/\"+str(number)):\n",
        "      os.makedirs(r\"/content/gdrive/My Drive/Colab Notebooks/Output/Outer/\"+str(number)) \n",
        "    cv2.imwrite(r\"/content/gdrive/My Drive/Colab Notebooks/Output/Outer/\"+str(number)+\"/img\"+str(count)+\".jpg\",img[y:y+h,x:x+w])\n",
        "    inner_box(img[y:y+h,x:x+w],count,height)\n",
        "    #print(count)\n",
        "    time.sleep(0.001)\n",
        "    count+=1\n",
        "  # except:\n",
        "  #   continue"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count is 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 1925.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(6, 6084)\n",
            "Predicting\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "count is 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 87/87 [00:00<00:00, 2519.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(87, 6084)\n",
            "Predicting\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "count is 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [00:00<00:00, 2665.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(239, 6084)\n",
            "Predicting\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "count is 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:00<00:00, 2732.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(114, 6084)\n",
            "Predicting\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "count is 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:00<00:00, 2565.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(30, 6084)\n",
            "Predicting\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "count is 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 55/55 [00:00<00:00, 2871.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(55, 6084)\n",
            "Predicting\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}